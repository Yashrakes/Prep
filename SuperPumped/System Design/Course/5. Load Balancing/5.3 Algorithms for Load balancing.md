# Algorithms/Traffic Routing Approaches Leveraged by Load Balancers

## Round Robin and Weighted Round Robin

- We know that the _Round Robin algorithm_ sends _IP addresses_ of machines sequentially to the clients. Parameters on the servers, such as _load_, their _CPU consumption_, and so on, are not taken into account when sending the _IP addresses_ to the clients.

- We have another approach known as the _Weighted Round Robin_ where based on the _server’s compute_ and _traffic handling capacity_ weights are assigned to them. And then, based on server weights, traffic is routed to them using the _Round Robin algorithm_.

- With this approach, more traffic is converged to machines that can handle a higher traffic load, thus efficiently using the resources.

- This approach is pretty useful when the service is deployed in different data centers having different compute capacities. More traffic can be directed to the larger data centers containing more machines.

---

## Least connections

- When using this algorithm, the traffic is routed to the machine that has the least open connections of all the machines in the cluster. There are two approaches to implement this.

- In the first, it is assumed that all the requests will consume an equal amount of server resources, and the traffic is routed to the machine with the least open connections based on this assumption.

- Now, in this scenario, there is a possibility that the machine with the least open connections might already be processing requests demanding most of its _CPU_ power. Routing more traffic to this machine would not be a good idea.

- In the other approach, the _CPU utilization_ and the _request processing time_ of the chosen machine is also taken into account before routing the traffic to it. Machines with the shortest request processing time, smallest CPU utilization, and the least open connections are the right candidates to process future client requests.

- The least connections approach comes in handy when the server has long opened connections. For instance, consider persistent connections in a gaming application.

---

## Random

- Following this approach, the traffic is randomly routed to the servers. The load balancer may also find similar servers in terms of existing load, request processing time, and so on. Then it randomly routes the traffic to these machines.

---

## Hash

- In this approach, the _source IP_ where the request is coming from and the request URL are hashed to route the traffic to the backend servers.

- Hashing the _source IP_ ensures that the request of a client with a certain _IP_ will always be routed to the same server.

- This facilitates a better user experience as the server has already processed the initial client requests and holds the client’s data in its local memory. There is no need for it to fetch the client session data from the session memory of the cluster and process the request. This reduces latency.

- Hashing the _client IP_ also enables the client to re-establish the connection with the same server, that was processing its request in case the connection drops.

- Hashing a _URL_ ensures that the request with that _URL_ always hits a certain cache that already has data on it. This is to ensure that there is no cache miss.

- This also averts the need for duplicating data in every cache and is, thus, a more efficient way to implement caching.

---